{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "eKg6xqD81Cok"
      },
      "outputs": [],
      "source": [
        "trainProcessed = pd.read_csv(\"./processedData/trainProcessed.csv\", )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>seri escapad demonstr adag good goos good gand...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>quiet introspect entertain independ worth seek</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>82</td>\n",
              "      <td>3</td>\n",
              "      <td>fan ismail merchant work suspect hard time sit</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>117</td>\n",
              "      <td>4</td>\n",
              "      <td>posit thrill combin ethnographi intrigu betray...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>157</td>\n",
              "      <td>5</td>\n",
              "      <td>aggress self glorif manipul whitewash</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8524</th>\n",
              "      <td>155985</td>\n",
              "      <td>8540</td>\n",
              "      <td>will claustrophob concept</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8525</th>\n",
              "      <td>155998</td>\n",
              "      <td>8541</td>\n",
              "      <td>despit annoy capabl clayburgh tambor great job...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8526</th>\n",
              "      <td>156022</td>\n",
              "      <td>8542</td>\n",
              "      <td>tri parodi genr joke unit state</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8527</th>\n",
              "      <td>156032</td>\n",
              "      <td>8543</td>\n",
              "      <td>movi downfal substitut plot person</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8528</th>\n",
              "      <td>156040</td>\n",
              "      <td>8544</td>\n",
              "      <td>film darkli atmospher herrmann quietli suggest...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8497 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      PhraseId  SentenceId                                             Phrase  \\\n",
              "0            1           1  seri escapad demonstr adag good goos good gand...   \n",
              "1           64           2     quiet introspect entertain independ worth seek   \n",
              "2           82           3     fan ismail merchant work suspect hard time sit   \n",
              "3          117           4  posit thrill combin ethnographi intrigu betray...   \n",
              "4          157           5              aggress self glorif manipul whitewash   \n",
              "...        ...         ...                                                ...   \n",
              "8524    155985        8540                          will claustrophob concept   \n",
              "8525    155998        8541  despit annoy capabl clayburgh tambor great job...   \n",
              "8526    156022        8542                    tri parodi genr joke unit state   \n",
              "8527    156032        8543                 movi downfal substitut plot person   \n",
              "8528    156040        8544  film darkli atmospher herrmann quietli suggest...   \n",
              "\n",
              "      Sentiment  \n",
              "0             1  \n",
              "1             4  \n",
              "2             1  \n",
              "3             3  \n",
              "4             1  \n",
              "...         ...  \n",
              "8524          2  \n",
              "8525          2  \n",
              "8526          1  \n",
              "8527          1  \n",
              "8528          2  \n",
              "\n",
              "[8497 rows x 4 columns]"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainProcessed[trainProcessed['Phrase'].notnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "aux = trainProcessed[trainProcessed['Phrase'].notnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of       PhraseId  SentenceId                                             Phrase  \\\n",
              "0            1           1  seri escapad demonstr adag good goos good gand...   \n",
              "1           64           2     quiet introspect entertain independ worth seek   \n",
              "2           82           3     fan ismail merchant work suspect hard time sit   \n",
              "3          117           4  posit thrill combin ethnographi intrigu betray...   \n",
              "4          157           5              aggress self glorif manipul whitewash   \n",
              "...        ...         ...                                                ...   \n",
              "8524    155985        8540                          will claustrophob concept   \n",
              "8525    155998        8541  despit annoy capabl clayburgh tambor great job...   \n",
              "8526    156022        8542                    tri parodi genr joke unit state   \n",
              "8527    156032        8543                 movi downfal substitut plot person   \n",
              "8528    156040        8544  film darkli atmospher herrmann quietli suggest...   \n",
              "\n",
              "      Sentiment  \n",
              "0             1  \n",
              "1             4  \n",
              "2             1  \n",
              "3             3  \n",
              "4             1  \n",
              "...         ...  \n",
              "8524          2  \n",
              "8525          2  \n",
              "8526          1  \n",
              "8527          1  \n",
              "8528          2  \n",
              "\n",
              "[8497 rows x 4 columns]>"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aux.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = aux.loc[:, [\"Phrase\"]]\n",
        "y = aux.loc[:, [\"Sentiment\"]]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 27, train_size = 0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'> \n",
            " 6797 \n",
            " <class 'str'>\n"
          ]
        }
      ],
      "source": [
        "x_train = list(x_train[\"Phrase\"])\n",
        "print(type(x_train), \"\\n\", len(x_train), \"\\n\", type(x_train[0]))\n",
        "\n",
        "x_test = list(x_test[\"Phrase\"])\n",
        "print(type(x_test), \"\\n\", len(x_test), \"\\n\", type(x_test[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorizer=CountVectorizer(min_df=1)\n",
        "\n",
        "dtmTF_train = vectorizer.fit_transform(x_train)\n",
        "df_tf_train = pd.DataFrame(dtmTF_train.toarray(), index=range(0, dtmTF_train.shape[0]), columns=vectorizer.get_feature_names())\n",
        "df_tf_train.head(10)\n",
        "\n",
        "dtmTF_test = vectorizer.fit_transform(x_test)\n",
        "df_tf_test = pd.DataFrame(dtmTF_test.toarray(), index=range(0, dtmTF_test.shape[0]), columns=vectorizer.get_feature_names())\n",
        "df_tf_test.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<6797x9214 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 56582 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "dtmTF_IDF_train = tfidf_transformer.fit_transform(dtmTF_train)\n",
        "\n",
        "df_tf_idf_train = pd.DataFrame(dtmTF_IDF_train.toarray(), index=range(0, dtmTF_IDF_train.shape[0]), columns=vectorizer.get_feature_names())\n",
        "df_tf_idf_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "dtmTF_IDF_test = tfidf_transformer.fit_transform(dtmTF_test)\n",
        "\n",
        "df_tf_idf_test = pd.DataFrame(dtmTF_IDF_test.toarray(), index=range(0, dtmTF_IDF_test.shape[0]), columns=vectorizer.get_feature_names())\n",
        "df_tf_idf_test.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "lsa = TruncatedSVD(25, algorithm='randomized')\n",
        "dtm_lsa_tf_train = lsa.fit_transform(dtmTF_train)\n",
        "dtm_lsa_tf_train = Normalizer(copy=False).fit_transform(dtm_lsa_tf_train)\n",
        "\n",
        "dtm_lsa_tf_idf_train = lsa.fit_transform(dtmTF_IDF_train)\n",
        "dtm_lsa_tf_idf_train = Normalizer(copy=False).fit_transform(dtm_lsa_tf_idf_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lsa = TruncatedSVD(25, algorithm='randomized')\n",
        "dtm_lsa_tf_test = lsa.fit_transform(dtmTF_test)\n",
        "dtm_lsa_tf_test = Normalizer(copy=False).fit_transform(dtm_lsa_tf_test)\n",
        "\n",
        "dtm_lsa_tf_idf_test = lsa.fit_transform(dtmTF_IDF_test)\n",
        "dtm_lsa_tf_idf_test = Normalizer(copy=False).fit_transform(dtm_lsa_tf_idf_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6797\n",
            "(6797, 25)\n"
          ]
        }
      ],
      "source": [
        "print(dtm_lsa_tf_train.shape[0])\n",
        "print(dtm_lsa_tf_idf_train.shape)\n",
        "\n",
        "print(dtm_lsa_tf_test.shape[0])\n",
        "print(dtm_lsa_tf_idf_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.403043</td>\n",
              "      <td>0.022870</td>\n",
              "      <td>0.053479</td>\n",
              "      <td>0.344231</td>\n",
              "      <td>-0.087819</td>\n",
              "      <td>0.158178</td>\n",
              "      <td>-0.161666</td>\n",
              "      <td>0.395887</td>\n",
              "      <td>-0.121862</td>\n",
              "      <td>0.007871</td>\n",
              "      <td>...</td>\n",
              "      <td>0.147136</td>\n",
              "      <td>0.277966</td>\n",
              "      <td>0.210963</td>\n",
              "      <td>-0.206989</td>\n",
              "      <td>-0.148562</td>\n",
              "      <td>-0.041655</td>\n",
              "      <td>-0.121851</td>\n",
              "      <td>0.129230</td>\n",
              "      <td>-0.087253</td>\n",
              "      <td>-0.136891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.377101</td>\n",
              "      <td>-0.505138</td>\n",
              "      <td>-0.129687</td>\n",
              "      <td>-0.055187</td>\n",
              "      <td>-0.072034</td>\n",
              "      <td>-0.044365</td>\n",
              "      <td>-0.001141</td>\n",
              "      <td>0.072722</td>\n",
              "      <td>0.004313</td>\n",
              "      <td>-0.052363</td>\n",
              "      <td>...</td>\n",
              "      <td>0.184976</td>\n",
              "      <td>0.094777</td>\n",
              "      <td>-0.176262</td>\n",
              "      <td>-0.308334</td>\n",
              "      <td>-0.497129</td>\n",
              "      <td>-0.035795</td>\n",
              "      <td>0.121741</td>\n",
              "      <td>-0.031653</td>\n",
              "      <td>0.047602</td>\n",
              "      <td>0.244803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.094139</td>\n",
              "      <td>-0.023511</td>\n",
              "      <td>0.081116</td>\n",
              "      <td>0.118826</td>\n",
              "      <td>-0.119323</td>\n",
              "      <td>0.069488</td>\n",
              "      <td>-0.075302</td>\n",
              "      <td>0.089659</td>\n",
              "      <td>0.804431</td>\n",
              "      <td>0.033744</td>\n",
              "      <td>...</td>\n",
              "      <td>0.037873</td>\n",
              "      <td>-0.073967</td>\n",
              "      <td>-0.005969</td>\n",
              "      <td>0.017766</td>\n",
              "      <td>-0.055868</td>\n",
              "      <td>-0.006735</td>\n",
              "      <td>-0.001204</td>\n",
              "      <td>-0.035344</td>\n",
              "      <td>0.045233</td>\n",
              "      <td>0.018746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.115805</td>\n",
              "      <td>-0.015486</td>\n",
              "      <td>0.088388</td>\n",
              "      <td>0.097512</td>\n",
              "      <td>-0.113996</td>\n",
              "      <td>0.053163</td>\n",
              "      <td>-0.042607</td>\n",
              "      <td>0.194611</td>\n",
              "      <td>0.046485</td>\n",
              "      <td>0.049647</td>\n",
              "      <td>...</td>\n",
              "      <td>0.477383</td>\n",
              "      <td>-0.347421</td>\n",
              "      <td>-0.252148</td>\n",
              "      <td>-0.267533</td>\n",
              "      <td>-0.448127</td>\n",
              "      <td>0.041382</td>\n",
              "      <td>0.064150</td>\n",
              "      <td>-0.055985</td>\n",
              "      <td>0.085919</td>\n",
              "      <td>0.234095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.218291</td>\n",
              "      <td>-0.081384</td>\n",
              "      <td>0.854268</td>\n",
              "      <td>-0.312855</td>\n",
              "      <td>0.163951</td>\n",
              "      <td>-0.080380</td>\n",
              "      <td>-0.003272</td>\n",
              "      <td>-0.004793</td>\n",
              "      <td>-0.095412</td>\n",
              "      <td>0.059640</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018279</td>\n",
              "      <td>-0.010864</td>\n",
              "      <td>0.030128</td>\n",
              "      <td>-0.003005</td>\n",
              "      <td>-0.084226</td>\n",
              "      <td>-0.116521</td>\n",
              "      <td>0.001302</td>\n",
              "      <td>0.027901</td>\n",
              "      <td>-0.024412</td>\n",
              "      <td>-0.003349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.124962</td>\n",
              "      <td>-0.036658</td>\n",
              "      <td>0.106687</td>\n",
              "      <td>0.235398</td>\n",
              "      <td>-0.112398</td>\n",
              "      <td>0.745514</td>\n",
              "      <td>0.538715</td>\n",
              "      <td>-0.128713</td>\n",
              "      <td>-0.105911</td>\n",
              "      <td>0.036541</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004858</td>\n",
              "      <td>0.009497</td>\n",
              "      <td>-0.064227</td>\n",
              "      <td>0.077408</td>\n",
              "      <td>-0.041284</td>\n",
              "      <td>-0.024648</td>\n",
              "      <td>0.050460</td>\n",
              "      <td>-0.037605</td>\n",
              "      <td>0.007420</td>\n",
              "      <td>-0.055782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.107905</td>\n",
              "      <td>-0.040546</td>\n",
              "      <td>0.242350</td>\n",
              "      <td>0.045072</td>\n",
              "      <td>0.043227</td>\n",
              "      <td>0.056116</td>\n",
              "      <td>-0.002781</td>\n",
              "      <td>-0.134161</td>\n",
              "      <td>0.270991</td>\n",
              "      <td>-0.427846</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054432</td>\n",
              "      <td>-0.018269</td>\n",
              "      <td>0.047096</td>\n",
              "      <td>-0.020312</td>\n",
              "      <td>0.093867</td>\n",
              "      <td>0.021323</td>\n",
              "      <td>-0.036955</td>\n",
              "      <td>0.042233</td>\n",
              "      <td>0.014605</td>\n",
              "      <td>-0.014589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.213645</td>\n",
              "      <td>0.098951</td>\n",
              "      <td>0.113127</td>\n",
              "      <td>0.196795</td>\n",
              "      <td>-0.162533</td>\n",
              "      <td>0.218391</td>\n",
              "      <td>-0.104470</td>\n",
              "      <td>0.161945</td>\n",
              "      <td>0.152869</td>\n",
              "      <td>0.072816</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.064880</td>\n",
              "      <td>0.096812</td>\n",
              "      <td>0.052023</td>\n",
              "      <td>-0.271742</td>\n",
              "      <td>-0.189888</td>\n",
              "      <td>-0.096726</td>\n",
              "      <td>-0.357539</td>\n",
              "      <td>-0.036331</td>\n",
              "      <td>0.133766</td>\n",
              "      <td>-0.214130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.092492</td>\n",
              "      <td>-0.022661</td>\n",
              "      <td>0.064938</td>\n",
              "      <td>0.100369</td>\n",
              "      <td>-0.031023</td>\n",
              "      <td>0.076655</td>\n",
              "      <td>-0.056300</td>\n",
              "      <td>0.186518</td>\n",
              "      <td>0.005693</td>\n",
              "      <td>0.103393</td>\n",
              "      <td>...</td>\n",
              "      <td>0.448582</td>\n",
              "      <td>-0.648907</td>\n",
              "      <td>-0.193767</td>\n",
              "      <td>0.002162</td>\n",
              "      <td>-0.075379</td>\n",
              "      <td>0.111395</td>\n",
              "      <td>-0.107026</td>\n",
              "      <td>-0.077587</td>\n",
              "      <td>0.043182</td>\n",
              "      <td>-0.037117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.196395</td>\n",
              "      <td>0.042851</td>\n",
              "      <td>0.094373</td>\n",
              "      <td>0.190006</td>\n",
              "      <td>-0.401215</td>\n",
              "      <td>-0.088153</td>\n",
              "      <td>-0.247985</td>\n",
              "      <td>-0.075817</td>\n",
              "      <td>0.149061</td>\n",
              "      <td>-0.007339</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008184</td>\n",
              "      <td>-0.064922</td>\n",
              "      <td>0.008440</td>\n",
              "      <td>0.182034</td>\n",
              "      <td>0.063074</td>\n",
              "      <td>-0.046841</td>\n",
              "      <td>-0.009867</td>\n",
              "      <td>0.397953</td>\n",
              "      <td>-0.161153</td>\n",
              "      <td>-0.581798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.403043  0.022870  0.053479  0.344231 -0.087819  0.158178 -0.161666   \n",
              "1  0.377101 -0.505138 -0.129687 -0.055187 -0.072034 -0.044365 -0.001141   \n",
              "2  0.094139 -0.023511  0.081116  0.118826 -0.119323  0.069488 -0.075302   \n",
              "3  0.115805 -0.015486  0.088388  0.097512 -0.113996  0.053163 -0.042607   \n",
              "4  0.218291 -0.081384  0.854268 -0.312855  0.163951 -0.080380 -0.003272   \n",
              "5  0.124962 -0.036658  0.106687  0.235398 -0.112398  0.745514  0.538715   \n",
              "6  0.107905 -0.040546  0.242350  0.045072  0.043227  0.056116 -0.002781   \n",
              "7  0.213645  0.098951  0.113127  0.196795 -0.162533  0.218391 -0.104470   \n",
              "8  0.092492 -0.022661  0.064938  0.100369 -0.031023  0.076655 -0.056300   \n",
              "9  0.196395  0.042851  0.094373  0.190006 -0.401215 -0.088153 -0.247985   \n",
              "\n",
              "         7         8         9   ...        15        16        17        18  \\\n",
              "0  0.395887 -0.121862  0.007871  ...  0.147136  0.277966  0.210963 -0.206989   \n",
              "1  0.072722  0.004313 -0.052363  ...  0.184976  0.094777 -0.176262 -0.308334   \n",
              "2  0.089659  0.804431  0.033744  ...  0.037873 -0.073967 -0.005969  0.017766   \n",
              "3  0.194611  0.046485  0.049647  ...  0.477383 -0.347421 -0.252148 -0.267533   \n",
              "4 -0.004793 -0.095412  0.059640  ... -0.018279 -0.010864  0.030128 -0.003005   \n",
              "5 -0.128713 -0.105911  0.036541  ... -0.004858  0.009497 -0.064227  0.077408   \n",
              "6 -0.134161  0.270991 -0.427846  ...  0.054432 -0.018269  0.047096 -0.020312   \n",
              "7  0.161945  0.152869  0.072816  ... -0.064880  0.096812  0.052023 -0.271742   \n",
              "8  0.186518  0.005693  0.103393  ...  0.448582 -0.648907 -0.193767  0.002162   \n",
              "9 -0.075817  0.149061 -0.007339  ... -0.008184 -0.064922  0.008440  0.182034   \n",
              "\n",
              "         19        20        21        22        23        24  \n",
              "0 -0.148562 -0.041655 -0.121851  0.129230 -0.087253 -0.136891  \n",
              "1 -0.497129 -0.035795  0.121741 -0.031653  0.047602  0.244803  \n",
              "2 -0.055868 -0.006735 -0.001204 -0.035344  0.045233  0.018746  \n",
              "3 -0.448127  0.041382  0.064150 -0.055985  0.085919  0.234095  \n",
              "4 -0.084226 -0.116521  0.001302  0.027901 -0.024412 -0.003349  \n",
              "5 -0.041284 -0.024648  0.050460 -0.037605  0.007420 -0.055782  \n",
              "6  0.093867  0.021323 -0.036955  0.042233  0.014605 -0.014589  \n",
              "7 -0.189888 -0.096726 -0.357539 -0.036331  0.133766 -0.214130  \n",
              "8 -0.075379  0.111395 -0.107026 -0.077587  0.043182 -0.037117  \n",
              "9  0.063074 -0.046841 -0.009867  0.397953 -0.161153 -0.581798  \n",
              "\n",
              "[10 rows x 25 columns]"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_lsa_tf_train = pd.DataFrame(dtm_lsa_tf_train, index=range(0, dtm_lsa_tf_train.shape[0]))\n",
        "df_lsa_tf_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_lsa_tf_test = pd.DataFrame(dtm_lsa_tf_test, index=range(0, dtm_lsa_tf_test.shape[0]))\n",
        "df_lsa_tf_test.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.429345</td>\n",
              "      <td>-0.232455</td>\n",
              "      <td>-0.000359</td>\n",
              "      <td>0.028924</td>\n",
              "      <td>0.072200</td>\n",
              "      <td>0.006151</td>\n",
              "      <td>0.262607</td>\n",
              "      <td>-0.199899</td>\n",
              "      <td>0.028455</td>\n",
              "      <td>0.320294</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.261215</td>\n",
              "      <td>-0.128806</td>\n",
              "      <td>0.144967</td>\n",
              "      <td>0.169382</td>\n",
              "      <td>0.121002</td>\n",
              "      <td>0.200028</td>\n",
              "      <td>-0.185936</td>\n",
              "      <td>-0.027604</td>\n",
              "      <td>0.118641</td>\n",
              "      <td>-0.382399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.389206</td>\n",
              "      <td>0.286037</td>\n",
              "      <td>-0.096905</td>\n",
              "      <td>-0.029026</td>\n",
              "      <td>-0.088621</td>\n",
              "      <td>-0.124818</td>\n",
              "      <td>0.017487</td>\n",
              "      <td>-0.121495</td>\n",
              "      <td>-0.106671</td>\n",
              "      <td>0.032867</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.074582</td>\n",
              "      <td>-0.422571</td>\n",
              "      <td>0.509370</td>\n",
              "      <td>-0.022132</td>\n",
              "      <td>-0.332603</td>\n",
              "      <td>-0.219315</td>\n",
              "      <td>0.072673</td>\n",
              "      <td>0.033523</td>\n",
              "      <td>0.105573</td>\n",
              "      <td>-0.164157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.166976</td>\n",
              "      <td>-0.032655</td>\n",
              "      <td>-0.023663</td>\n",
              "      <td>0.122479</td>\n",
              "      <td>0.067591</td>\n",
              "      <td>-0.174236</td>\n",
              "      <td>0.305702</td>\n",
              "      <td>0.881973</td>\n",
              "      <td>-0.047975</td>\n",
              "      <td>-0.007792</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018299</td>\n",
              "      <td>-0.011103</td>\n",
              "      <td>0.005850</td>\n",
              "      <td>-0.055412</td>\n",
              "      <td>0.024147</td>\n",
              "      <td>-0.077173</td>\n",
              "      <td>0.040630</td>\n",
              "      <td>0.016104</td>\n",
              "      <td>0.049165</td>\n",
              "      <td>-0.079698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.187316</td>\n",
              "      <td>-0.075576</td>\n",
              "      <td>-0.042341</td>\n",
              "      <td>0.122370</td>\n",
              "      <td>0.079286</td>\n",
              "      <td>-0.011455</td>\n",
              "      <td>0.090386</td>\n",
              "      <td>-0.108745</td>\n",
              "      <td>-0.037433</td>\n",
              "      <td>0.016573</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.268091</td>\n",
              "      <td>-0.438429</td>\n",
              "      <td>0.492580</td>\n",
              "      <td>-0.059029</td>\n",
              "      <td>0.276173</td>\n",
              "      <td>-0.319233</td>\n",
              "      <td>0.301158</td>\n",
              "      <td>0.074460</td>\n",
              "      <td>0.016698</td>\n",
              "      <td>-0.106560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.320701</td>\n",
              "      <td>-0.062341</td>\n",
              "      <td>-0.127004</td>\n",
              "      <td>0.659704</td>\n",
              "      <td>0.000925</td>\n",
              "      <td>0.388488</td>\n",
              "      <td>-0.344448</td>\n",
              "      <td>0.026536</td>\n",
              "      <td>-0.119746</td>\n",
              "      <td>0.017186</td>\n",
              "      <td>...</td>\n",
              "      <td>0.074801</td>\n",
              "      <td>-0.053916</td>\n",
              "      <td>0.133949</td>\n",
              "      <td>-0.083932</td>\n",
              "      <td>0.042956</td>\n",
              "      <td>-0.049586</td>\n",
              "      <td>-0.004941</td>\n",
              "      <td>-0.100509</td>\n",
              "      <td>-0.077832</td>\n",
              "      <td>0.050262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.214469</td>\n",
              "      <td>-0.029597</td>\n",
              "      <td>0.108346</td>\n",
              "      <td>0.179935</td>\n",
              "      <td>0.157724</td>\n",
              "      <td>-0.128424</td>\n",
              "      <td>0.199733</td>\n",
              "      <td>-0.135254</td>\n",
              "      <td>0.736038</td>\n",
              "      <td>-0.074715</td>\n",
              "      <td>...</td>\n",
              "      <td>0.151047</td>\n",
              "      <td>0.008236</td>\n",
              "      <td>0.044288</td>\n",
              "      <td>0.055877</td>\n",
              "      <td>-0.099476</td>\n",
              "      <td>-0.085145</td>\n",
              "      <td>-0.062294</td>\n",
              "      <td>-0.081141</td>\n",
              "      <td>-0.185250</td>\n",
              "      <td>-0.085637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.195699</td>\n",
              "      <td>-0.023624</td>\n",
              "      <td>0.025919</td>\n",
              "      <td>0.291958</td>\n",
              "      <td>0.068321</td>\n",
              "      <td>0.075574</td>\n",
              "      <td>-0.144664</td>\n",
              "      <td>0.018069</td>\n",
              "      <td>0.011535</td>\n",
              "      <td>-0.069192</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.145372</td>\n",
              "      <td>0.034753</td>\n",
              "      <td>0.176128</td>\n",
              "      <td>0.188227</td>\n",
              "      <td>0.285502</td>\n",
              "      <td>0.091769</td>\n",
              "      <td>-0.143680</td>\n",
              "      <td>-0.006315</td>\n",
              "      <td>-0.157121</td>\n",
              "      <td>-0.109138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.343843</td>\n",
              "      <td>-0.333799</td>\n",
              "      <td>-0.049489</td>\n",
              "      <td>0.195323</td>\n",
              "      <td>0.164894</td>\n",
              "      <td>-0.043868</td>\n",
              "      <td>0.222108</td>\n",
              "      <td>-0.213281</td>\n",
              "      <td>0.070126</td>\n",
              "      <td>0.286247</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.056523</td>\n",
              "      <td>0.024443</td>\n",
              "      <td>0.099619</td>\n",
              "      <td>0.309945</td>\n",
              "      <td>-0.055675</td>\n",
              "      <td>0.024884</td>\n",
              "      <td>-0.083916</td>\n",
              "      <td>-0.346220</td>\n",
              "      <td>0.336473</td>\n",
              "      <td>0.017853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.138981</td>\n",
              "      <td>-0.033454</td>\n",
              "      <td>-0.004165</td>\n",
              "      <td>0.050833</td>\n",
              "      <td>0.108971</td>\n",
              "      <td>0.025605</td>\n",
              "      <td>0.047173</td>\n",
              "      <td>-0.072071</td>\n",
              "      <td>0.022821</td>\n",
              "      <td>0.054319</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.176987</td>\n",
              "      <td>-0.201983</td>\n",
              "      <td>0.124124</td>\n",
              "      <td>0.022033</td>\n",
              "      <td>0.674775</td>\n",
              "      <td>-0.268500</td>\n",
              "      <td>0.200156</td>\n",
              "      <td>-0.118853</td>\n",
              "      <td>-0.110034</td>\n",
              "      <td>0.361700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.257952</td>\n",
              "      <td>-0.189155</td>\n",
              "      <td>-0.157326</td>\n",
              "      <td>0.219186</td>\n",
              "      <td>0.060134</td>\n",
              "      <td>-0.221628</td>\n",
              "      <td>0.349377</td>\n",
              "      <td>0.111426</td>\n",
              "      <td>-0.184287</td>\n",
              "      <td>0.043425</td>\n",
              "      <td>...</td>\n",
              "      <td>0.237318</td>\n",
              "      <td>0.029240</td>\n",
              "      <td>-0.339096</td>\n",
              "      <td>-0.342512</td>\n",
              "      <td>-0.015455</td>\n",
              "      <td>0.046336</td>\n",
              "      <td>0.136289</td>\n",
              "      <td>-0.451059</td>\n",
              "      <td>-0.169902</td>\n",
              "      <td>0.070751</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.429345 -0.232455 -0.000359  0.028924  0.072200  0.006151  0.262607   \n",
              "1  0.389206  0.286037 -0.096905 -0.029026 -0.088621 -0.124818  0.017487   \n",
              "2  0.166976 -0.032655 -0.023663  0.122479  0.067591 -0.174236  0.305702   \n",
              "3  0.187316 -0.075576 -0.042341  0.122370  0.079286 -0.011455  0.090386   \n",
              "4  0.320701 -0.062341 -0.127004  0.659704  0.000925  0.388488 -0.344448   \n",
              "5  0.214469 -0.029597  0.108346  0.179935  0.157724 -0.128424  0.199733   \n",
              "6  0.195699 -0.023624  0.025919  0.291958  0.068321  0.075574 -0.144664   \n",
              "7  0.343843 -0.333799 -0.049489  0.195323  0.164894 -0.043868  0.222108   \n",
              "8  0.138981 -0.033454 -0.004165  0.050833  0.108971  0.025605  0.047173   \n",
              "9  0.257952 -0.189155 -0.157326  0.219186  0.060134 -0.221628  0.349377   \n",
              "\n",
              "         7         8         9   ...        15        16        17        18  \\\n",
              "0 -0.199899  0.028455  0.320294  ... -0.261215 -0.128806  0.144967  0.169382   \n",
              "1 -0.121495 -0.106671  0.032867  ... -0.074582 -0.422571  0.509370 -0.022132   \n",
              "2  0.881973 -0.047975 -0.007792  ... -0.018299 -0.011103  0.005850 -0.055412   \n",
              "3 -0.108745 -0.037433  0.016573  ... -0.268091 -0.438429  0.492580 -0.059029   \n",
              "4  0.026536 -0.119746  0.017186  ...  0.074801 -0.053916  0.133949 -0.083932   \n",
              "5 -0.135254  0.736038 -0.074715  ...  0.151047  0.008236  0.044288  0.055877   \n",
              "6  0.018069  0.011535 -0.069192  ... -0.145372  0.034753  0.176128  0.188227   \n",
              "7 -0.213281  0.070126  0.286247  ... -0.056523  0.024443  0.099619  0.309945   \n",
              "8 -0.072071  0.022821  0.054319  ... -0.176987 -0.201983  0.124124  0.022033   \n",
              "9  0.111426 -0.184287  0.043425  ...  0.237318  0.029240 -0.339096 -0.342512   \n",
              "\n",
              "         19        20        21        22        23        24  \n",
              "0  0.121002  0.200028 -0.185936 -0.027604  0.118641 -0.382399  \n",
              "1 -0.332603 -0.219315  0.072673  0.033523  0.105573 -0.164157  \n",
              "2  0.024147 -0.077173  0.040630  0.016104  0.049165 -0.079698  \n",
              "3  0.276173 -0.319233  0.301158  0.074460  0.016698 -0.106560  \n",
              "4  0.042956 -0.049586 -0.004941 -0.100509 -0.077832  0.050262  \n",
              "5 -0.099476 -0.085145 -0.062294 -0.081141 -0.185250 -0.085637  \n",
              "6  0.285502  0.091769 -0.143680 -0.006315 -0.157121 -0.109138  \n",
              "7 -0.055675  0.024884 -0.083916 -0.346220  0.336473  0.017853  \n",
              "8  0.674775 -0.268500  0.200156 -0.118853 -0.110034  0.361700  \n",
              "9 -0.015455  0.046336  0.136289 -0.451059 -0.169902  0.070751  \n",
              "\n",
              "[10 rows x 25 columns]"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_lsa_tf_idf_train = pd.DataFrame(dtm_lsa_tf_idf_train, index=range(0, dtm_lsa_tf_idf_train.shape[0]))\n",
        "df_lsa_tf_idf_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_lsa_tf_idf_test = pd.DataFrame(dtm_lsa_tf_idf_test, index=range(0, dtm_lsa_tf_idf_test.shape[0]))\n",
        "df_lsa_tf_idf_test.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=10, random_state=27)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=10, random_state=27)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeRegressor(max_depth=10, random_state=27)"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regTF_train = DecisionTreeRegressor(max_depth = 10, random_state = 27)\n",
        "regTF_IDF_train = DecisionTreeRegressor(max_depth = 10, random_state = 27)\n",
        "\n",
        "regTF_train.fit(dtm_lsa_tf_train, y_train)\n",
        "regTF_IDF_train.fit(dtm_lsa_tf_idf_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regTF_test = DecisionTreeRegressor(max_depth = 10, random_state = 27)\n",
        "regTF_IDF_test = DecisionTreeRegressor(max_depth = 10, random_state = 27)\n",
        "\n",
        "regTF_test.fit(dtm_lsa_tf_test, y_test)\n",
        "regTF_IDF_test.fit(dtm_lsa_tf_idf_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regTF.predict()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SIA-2022.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
